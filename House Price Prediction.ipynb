{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle Competition\n",
    "\n",
    "## House Prices: Advanced Regression Techniques \n",
    "\n",
    "> Data can be found at https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import (RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor,\n",
    "RandomForestClassifier, ExtraTreesClassifier, GradientBoostingClassifier, AdaBoostClassifier)\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.max_rows', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp = pd.read_csv(r\"C:/Users/sastu/Downloads/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 81)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_holdout = pd.read_csv(r\"C:/Users/sastu/Downloads/test.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 80)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp_holdout.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# hp.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hp_holdout.isnull().sum() #some extra columns with missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imputation - Interval variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.LotFrontage.fillna(hp.LotFrontage.median(), inplace=True)\n",
    "hp.MasVnrArea.fillna(hp.MasVnrArea.median(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### need to impute missing values in the holdout sample with the same values that we used to impute missing values in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "LotFrontage_median = hp.LotFrontage.median()\n",
    "MasVnrArea_median = hp.MasVnrArea.median()\n",
    "BsmtFinSF1_median = hp.BsmtFinSF1.median()\n",
    "BsmtFinSF2_median = hp.BsmtFinSF2.median()\n",
    "BsmtUnfSF_median = hp.BsmtUnfSF.median()\n",
    "GarageArea_median = hp.GarageArea.median()\n",
    "TotalBsmtSF_median = hp.TotalBsmtSF.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_holdout.LotFrontage.fillna(LotFrontage_median, inplace=True)\n",
    "hp_holdout.MasVnrArea.fillna(MasVnrArea_median, inplace=True)\n",
    "hp_holdout.BsmtFinSF1.fillna(BsmtFinSF1_median, inplace=True)\n",
    "hp_holdout.BsmtFinSF2.fillna(BsmtFinSF2_median, inplace=True)\n",
    "hp_holdout.BsmtUnfSF.fillna(BsmtUnfSF_median, inplace=True)\n",
    "hp_holdout.GarageArea.fillna(GarageArea_median, inplace=True)\n",
    "hp_holdout.TotalBsmtSF.fillna(TotalBsmtSF_median, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imputation - categorical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp.MasVnrType.fillna(hp.MasVnrType.mode().item(),inplace=True)\n",
    "hp.BsmtQual.fillna(hp.BsmtQual.mode().item(),inplace=True)\n",
    "hp.BsmtCond.fillna(hp.BsmtCond.mode().item(),inplace=True)\n",
    "hp.BsmtExposure.fillna(hp.BsmtExposure.mode().item(),inplace=True)\n",
    "hp.BsmtFinType1.fillna(hp.BsmtFinType1.mode().item(),inplace=True)\n",
    "hp.BsmtFinType2.fillna(hp.BsmtFinType2.mode().item(),inplace=True)\n",
    "hp.Electrical.fillna(hp.Electrical.mode().item(),inplace=True)\n",
    "hp.FireplaceQu.fillna(hp.FireplaceQu.mode().item(),inplace=True)\n",
    "hp.GarageType.fillna(hp.GarageType.mode().item(),inplace=True)\n",
    "hp.GarageYrBlt.fillna(hp.GarageYrBlt.mode().item(),inplace=True)\n",
    "hp.GarageFinish.fillna(hp.GarageFinish.mode().item(),inplace=True)\n",
    "hp.GarageQual.fillna(hp.GarageQual.mode().item(),inplace=True)\n",
    "hp.GarageCond.fillna(hp.GarageCond.mode().item(),inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### need to impute missing values in the holdout sample with the same values that we used to impute the missing values in the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "MasVnrType_mode = hp.MasVnrType.mode().item()\n",
    "BsmtQual_mode = hp.BsmtQual.mode().item()\n",
    "BsmtCond_mode = hp.BsmtCond.mode().item()\n",
    "BsmtExposure_mode = hp.BsmtExposure.mode().item()\n",
    "BsmtFinType1_mode = hp.BsmtFinType1.mode().item()\n",
    "BsmtFinType2_mode = hp.BsmtFinType2.mode().item()\n",
    "Electrical_mode = hp.Electrical.mode().item()\n",
    "FireplaceQu_mode = hp.FireplaceQu.mode().item()\n",
    "GarageType_mode = hp.GarageType.mode().item()\n",
    "GarageYrBlt_mode = hp.GarageYrBlt.mode().item()\n",
    "GarageFinish_mode = hp.GarageFinish.mode().item()\n",
    "GarageQual_mode = hp.GarageQual.mode().item()\n",
    "GarageCond_mode = hp.GarageCond.mode().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_holdout.MasVnrType.fillna(MasVnrType_mode,inplace=True)\n",
    "hp_holdout.BsmtQual.fillna(BsmtQual_mode,inplace=True)\n",
    "hp_holdout.BsmtCond.fillna(BsmtCond_mode,inplace=True)\n",
    "hp_holdout.BsmtExposure.fillna(BsmtExposure_mode,inplace=True)\n",
    "hp_holdout.BsmtFinType1.fillna(BsmtFinType1_mode,inplace=True)\n",
    "hp_holdout.BsmtFinType2.fillna(BsmtFinType2_mode,inplace=True)\n",
    "hp_holdout.Electrical.fillna(Electrical_mode,inplace=True)\n",
    "hp_holdout.FireplaceQu.fillna(FireplaceQu_mode,inplace=True)\n",
    "hp_holdout.GarageType.fillna(GarageType_mode,inplace=True)\n",
    "hp_holdout.GarageYrBlt.fillna(GarageYrBlt_mode,inplace=True)\n",
    "hp_holdout.GarageFinish.fillna(GarageFinish_mode,inplace=True)\n",
    "hp_holdout.GarageQual.fillna(GarageQual_mode,inplace=True)\n",
    "hp_holdout.GarageCond.fillna(GarageCond_mode,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hp.isnull().sum() #no missing values left; remove rest of the variables with more than 70% missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hp_holdout.isnull().sum()  #no missing values left; remove rest of the variables with more than 70% missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1460, 81)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 80)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp_holdout.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp['train'] = 1\n",
    "hp_holdout['train'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:6211: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    }
   ],
   "source": [
    "hp_appended = hp.append(hp_holdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2919, 82)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp_appended.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "usa_gdp = pd.read_csv(r\"C:/Users/sastu/Downloads/USA_GDP.csv\") \n",
    "#as housing prices are affected by gdp growth, I have added gdp growth column (data obtained from online source - https://countryeconomy.com/gdp/usa?year=2007)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_appended = pd.merge(hp_appended, usa_gdp, how='left', on=['MoSold', 'YrSold'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_appended['TotalAgeOfHouse'] = hp_appended.YrSold - hp_appended.YearBuilt\n",
    "hp_appended['YearsToRemodelAfterBuilt'] = hp_appended.YearRemodAdd - hp_appended.YearBuilt\n",
    "hp_appended['YearsAfterRemodelBeforeSold'] = hp_appended.YrSold - hp_appended.YearRemodAdd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_appended['TotalSF'] = hp_appended['TotalBsmtSF'] + hp_appended['1stFlrSF'] + hp_appended['2ndFlrSF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_appended['QSold'] = 0 #Quarter in which the house was sold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = []\n",
    "for row in range(len(hp_appended)):\n",
    "    if (hp_appended['MoSold'][row] == 1 or hp_appended['MoSold'][row] == 2 or hp_appended['MoSold'][row] == 3):\n",
    "        q.append(1)\n",
    "    elif (hp_appended['MoSold'][row] == 4 or hp_appended['MoSold'][row] == 5 or hp_appended['MoSold'][row] == 6):\n",
    "        q.append(2)\n",
    "    elif (hp_appended['MoSold'][row] == 7 or hp_appended['MoSold'][row] == 8 or hp_appended['MoSold'][row] == 9):\n",
    "        q.append(3)\n",
    "    else:\n",
    "        q.append(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_appended['QSold'] = q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hp_appended.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2919, 88)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hp_appended.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creating dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in ['MSSubClass', 'MSZoning', 'Street', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope',\n",
    "       'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'OverallQual', 'OverallCond', 'RoofStyle',\n",
    "       'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond',\n",
    "       'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath',\n",
    "       'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual', 'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageCars', \n",
    "        'GarageQual', 'GarageCond', 'PavedDrive', 'MoSold', 'QSold', 'SaleType', 'SaleCondition']:\n",
    "    dummies = pd.get_dummies(hp_appended[column],prefix=column)\n",
    "    hp_appended[dummies.columns] = dummies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### removing variables with more than 70% missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_appended.drop(['Alley','PoolQC','Fence','MiscFeature'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### removing variables for which we created dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_appended_new = hp_appended.drop(['MSSubClass', 'MSZoning', 'Street', 'LotShape', 'LandContour', \n",
    "                  'Utilities', 'LotConfig', 'LandSlope','Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', \n",
    "                  'OverallQual', 'OverallCond', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', \n",
    "                  'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2',\n",
    "                  'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath',\n",
    "                  'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual', 'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'FireplaceQu', \n",
    "                  'GarageType', 'GarageFinish', 'GarageCars', 'QSold', 'GarageQual', 'GarageCond', 'PavedDrive', 'MoSold', 'SaleType', \n",
    "                  'SaleCondition'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### separate the data appended before into train and holdout samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp_train = hp_appended_new.loc[hp_appended_new.train == 1]\n",
    "hp_holdout = hp_appended_new.loc[hp_appended_new.train == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### transforming SalePrice using log10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:4405: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "hp_train.SalePrice = hp_train.SalePrice.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:4405: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "hp_train.SalePrice = np.log10(hp_train.SalePrice+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hp_train.SalePrice.plot.hist(bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create train and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(hp_train.drop('SalePrice', axis=1), hp_train.SalePrice, \n",
    "                                                      test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define a function to get model statistics like rmse for train/valid and r^2 for train/valid/out of bag samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cmath as math\n",
    "def rmse(x,y): return math.sqrt(((x-y)**2).mean())\n",
    "\n",
    "def print_score(m):\n",
    "    res = [rmse(m.predict(X_train), y_train), rmse(m.predict(X_valid), y_valid),\n",
    "                m.score(X_train, y_train), m.score(X_valid, y_valid)]\n",
    "    if hasattr(m, 'oob_score_'): res.append(m.oob_score_)\n",
    "    print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RF - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 485 ms\n",
      "[(0.0424551265124632+0j), (0.06438801645988602+0j), 0.9383476331777543, 0.8704304008079131, 0.8399603806706307]\n"
     ]
    }
   ],
   "source": [
    "model1 = RandomForestRegressor(n_estimators=50, n_jobs=-1, min_samples_leaf=5, oob_score=True)\n",
    "%time model1.fit(X_train, y_train)\n",
    "print_score(model1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RF - 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 587 ms\n",
      "[(0.03491347902913015+0j), (0.06175164329825944+0j), 0.9583057919318946, 0.8808236552504715, 0.8491361956843932]\n"
     ]
    }
   ],
   "source": [
    "model2 = RandomForestRegressor(n_estimators=100, n_jobs=-1, max_features=0.5, min_samples_leaf=3, oob_score=True)\n",
    "%time model2.fit(X_train, y_train)\n",
    "print_score(model2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## final prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred = model2.predict(hp_holdout.drop('SalePrice', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = 10**final_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:4405: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "hp_holdout.SalePrice = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hp_holdout.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_submission = hp_holdout[['Id', 'SalePrice']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459, 2)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_submission.to_csv(\"C:/Users/sastu/Downloads/final_submission.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
